# LLM 模型配置文件
# 每个模型一个配置节点，包含连接和使用的常用配置

# DeepSeek 系列
deepseek:
  deepseek-chat:
    name: "DeepSeek Chat"
    provider: "deepseek"
    model_name: "deepseek-chat"
    api_key: "sk-de5a1965cfa94ccea0eaad15d93251dc"
    base_url: "https://api.deepseek.com/v1"
    max_tokens: 4096
    temperature: 0.7
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
    timeout: 60
    max_retries: 3
    stream: true
    enabled: true
    description: "DeepSeek Chat 中文优化对话模型"
    tags: ["chinese", "chat", "reasoning"]

# 月之暗面系列
moonshot:
  moonshot-v1-8k:
    name: "moonshot-v1-8k"
    provider: "moonshot"
    model_name: "moonshot-v1-8k"
    api_key: "sk-5IPFajDv6yy8hWKd3DScOHea2HE10r1FTN6SMgz038ljsSTf"
    base_url: "https://api.moonshot.cn/v1"
    max_tokens: 8192
    temperature: 0.7
    top_p: 0.7
    timeout: 60
    max_retries: 3
    stream: true
    enabled: true
    description: "月之暗面通用大模型"
    tags: ["chinese", "general"]

# 阿里通义千问系列
alibaba:
  qwen-plus:
    name: "通义千问Plus"
    provider: "alibaba"
    model_name: "qwen-plus-2025-07-28"
    api_key: "sk-282660fdc8cc4460943f2da2a86d3d01"
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    max_tokens: 8192
    temperature: 0.7
    top_p: 0.8
    timeout: 60
    max_retries: 3
    stream: true
    enabled: true
    description: "阿里通义千问 Plus 中文对话模型"
    tags: ["chinese", "general", "multimodal"]

  qwen3-coder:
    name: "通义千问 Coder"
    provider: "alibaba"
    model_name: "qwen3-coder-plus"
    api_key: "sk-282660fdc8cc4460943f2da2a86d3d01"
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    max_tokens: 8192
    temperature: 0.7
    top_p: 0.8
    timeout: 60
    max_retries: 3
    stream: true
    enabled: true
    description: "阿里通义千问 Coder 中文对话模型"
    tags: ["chinese", "code"]

# 本地模型配置示例
local:
  ollama-qwen3-8b:
    name: "qwen3-8b"
    provider: "ollama"
    model_name: "qwen3:8b"
    api_key: "sk-ollamakey123"
    base_url: "http://localhost:11434/v1"
    max_tokens: 4096
    temperature: 0.7
    top_p: 0.9
    timeout: 120
    max_retries: 3
    stream: true
    enabled: true # 默认禁用，需要手动启用
    description: "本地部署的 qwen3 8B 模型"
    tags: ["local", "qwen", "opensource"]

  ollama-deeseek-8b:
    name: "deeseek-8b"
    provider: "ollama"
    model_name: "deepseek-r1:8b"
    api_key: "sk-ollamakey123"
    base_url: "http://localhost:11434/v1"
    max_tokens: 4096
    temperature: 0.7
    top_p: 0.9
    timeout: 120
    max_retries: 3
    stream: true
    enabled: true # 默认禁用，需要手动启用
    description: "本地部署的 deepseek 8B 模型"
    tags: ["local", "deepseek", "opensource"]

# 全局默认配置
defaults:
  timeout: 60
  max_retries: 3
  stream: true
  temperature: 0.7
  top_p: 1.0
  max_tokens: 4096
  enabled: true

# 配置文件元信息
metadata:
  version: "1.0.0"
  created_at: "2025-01-01"
  description: "LLM 模型统一配置文件"
  supported_providers: ["deepseek", "alibaba", "moonshot", "ollama"]
