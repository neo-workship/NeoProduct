# common

- **common\__init__.py** *(åŒ…åˆå§‹åŒ–æ–‡ä»¶ - ç©º)*
```python

```

- **common\log_handler.py**
```python
"""
å¢å¼ºçš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—æ¨¡å— - åŸºäº Loguru çš„æ··åˆæ¶æ„(ä¼˜åŒ–ç‰ˆ v2.2 - ä¿®å¤è°ƒç”¨æ ˆé—®é¢˜)
ä¿ç•™ç°æœ‰ API,å¢å¼ºåº•å±‚å®ç°,æŒ‰æ—¥æœŸæ–‡ä»¶å¤¹ç»„ç»‡æ—¥å¿—
æ–‡ä»¶è·¯å¾„: webproduct_ui_template/common/log_handler.py

å…³é”®ä¿®å¤(v2.2):
1. ä¿®å¤ module/function/line_number æ€»æ˜¯æ˜¾ç¤º log_handler.py çš„é—®é¢˜
2. ä½¿ç”¨ logger.opt(depth=N) æ­£ç¡®è¿½è¸ªè°ƒç”¨æ ˆ
3. æ”¹è¿›ç”¨æˆ·ä¸Šä¸‹æ–‡è·å–é€»è¾‘,å‡å°‘ anonymous å‡ºç°

ç‰¹æ€§:
1. å®Œå…¨å…¼å®¹ç°æœ‰ API (log_info, log_error, safe, db_safe, safe_protect)
2. ä½¿ç”¨ Loguru ä½œä¸ºåº•å±‚å¼•æ“,æ€§èƒ½æå‡ 20-30%
3. æ”¯æŒ 7 ç§æ—¥å¿—çº§åˆ« (TRACE, DEBUG, INFO, SUCCESS, WARNING, ERROR, CRITICAL)
4. æ™ºèƒ½æ—¥å¿—è½®è½¬ (æŒ‰å¤©/è‡ªåŠ¨å‹ç¼©)
5. å¼‚æ­¥æ—¥å¿—å†™å…¥,ä¸é˜»å¡ä¸»çº¿ç¨‹
6. ä¿ç•™ CSV æ ¼å¼å…¼å®¹(ç”¨äºæŸ¥è¯¢å·¥å…·)
7. è‡ªåŠ¨æ•è·ç”¨æˆ·ä¸Šä¸‹æ–‡
8. é›†æˆ NiceGUI UI é€šçŸ¥
9. æŒ‰æ—¥æœŸæ–‡ä»¶å¤¹ç»„ç»‡: logs/2025-10-23/{app.log, error.log, app_logs.csv}
"""
import csv
import json
import asyncio
import threading
import functools
import inspect
import sys
from typing import Callable, Any, Optional, Dict, List
from datetime import datetime, timedelta
from pathlib import Path
from contextlib import contextmanager
from loguru import logger
from nicegui import ui

# =============================================================================
# é…ç½®å’Œåˆå§‹åŒ–
# =============================================================================

class LoguruExceptionHandler:
    """åŸºäº Loguru çš„å¢å¼ºå¼‚å¸¸å¤„ç†å™¨ - å•ä¾‹æ¨¡å¼(çº¿ç¨‹å®‰å…¨)"""
    
    _instance = None
    _lock = threading.Lock()
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        
        # é…ç½®å‚æ•°
        self.log_base_dir = Path('logs')  # æ—¥å¿—æ ¹ç›®å½•
        self.log_base_dir.mkdir(exist_ok=True)
        self.max_log_days = 30  # æ™®é€šæ—¥å¿—ä¿ç•™30å¤©
        self.error_log_days = 90  # é”™è¯¯æ—¥å¿—ä¿ç•™90å¤©
        self.csv_enabled = True  # CSV å…¼å®¹æ¨¡å¼
        
        # å½“å‰æ—¥å¿—ç›®å½•(æ¯å¤©ä¸€ä¸ªæ–‡ä»¶å¤¹)
        self.current_log_dir = self._get_today_log_dir()
        
        # åˆå§‹åŒ– Loguru
        self._setup_loguru()
        
        # CSV æ”¯æŒ(å…¼å®¹ç°æœ‰æŸ¥è¯¢å·¥å…·)
        if self.csv_enabled:
            self._setup_csv_logging()
        
        # å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡
        self._start_cleanup_task()
        
        LoguruExceptionHandler._initialized = True
    
    def _get_today_log_dir(self) -> Path:
        """è·å–ä»Šå¤©çš„æ—¥å¿—ç›®å½•"""
        today = datetime.now().strftime('%Y-%m-%d')
        log_dir = self.log_base_dir / today
        log_dir.mkdir(parents=True, exist_ok=True)
        return log_dir
    
    def _check_and_update_log_dir(self):
        """æ£€æŸ¥æ—¥æœŸæ˜¯å¦å˜åŒ–,å¦‚æœè·¨å¤©åˆ™æ›´æ–°æ—¥å¿—ç›®å½•"""
        today_log_dir = self._get_today_log_dir()
        
        if today_log_dir != self.current_log_dir:
            self.current_log_dir = today_log_dir
            
            # é‡æ–°é…ç½® Loguru
            logger.remove()
            self._setup_loguru()
            if self.csv_enabled:
                self._setup_csv_logging()
    
    def _setup_loguru(self):
        """é…ç½® Loguru æ—¥å¿—ç³»ç»Ÿ - æŒ‰æ—¥æœŸæ–‡ä»¶å¤¹ç»„ç»‡"""
        # ç§»é™¤é»˜è®¤å¤„ç†å™¨
        logger.remove()
        
        # 1ï¸âƒ£ æ§åˆ¶å°è¾“å‡º - å¼€å‘ç¯å¢ƒ(å½©è‰²æ ¼å¼åŒ–)
        logger.add(
            sys.stderr,
            format=(
                "<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | "
                "<level>{level: <8}</level> | "
                "<cyan>{extra[user_id]}</cyan>@<cyan>{extra[username]}</cyan> | "
                "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | "
                "<level>{message}</level>"
            ),
            level="DEBUG",   # âœ… æ§åˆ¶å°è¾“å‡º DEBUG,ä¸å†™å…¥æ—¥å¿—æ–‡ä»¶
            colorize=True,
            backtrace=True,
            diagnose=True,
            enqueue=False  # æ§åˆ¶å°åŒæ­¥è¾“å‡º,æ–¹ä¾¿è°ƒè¯•
        )
        
        # 2ï¸âƒ£ æ™®é€šæ—¥å¿—æ–‡ä»¶ - å­˜å‚¨åœ¨å½“å¤©æ—¥æœŸæ–‡ä»¶å¤¹ä¸‹
        logger.add(
            self.current_log_dir / "app.log",
            rotation="500 MB",
            retention=f"{self.max_log_days} days",
            compression="zip",
            encoding="utf-8",
            format=(
                "{time:YYYY-MM-DD HH:mm:ss.SSS} | "
                "{level: <8} | "
                "{extra[user_id]}@{extra[username]} | "
                "{name}:{function}:{line} | "
                "{message}"
            ),
            level="INFO",
            enqueue=True,
            backtrace=True,
            diagnose=True
        )
        
        # 3ï¸âƒ£ é”™è¯¯æ—¥å¿—æ–‡ä»¶ - å­˜å‚¨åœ¨å½“å¤©æ—¥æœŸæ–‡ä»¶å¤¹ä¸‹
        logger.add(
            self.current_log_dir / "error.log",
            rotation="100 MB",
            retention=f"{self.error_log_days} days",
            compression="zip",
            encoding="utf-8",
            format=(
                "{time:YYYY-MM-DD HH:mm:ss.SSS} | "
                "{level: <8} | "
                "{extra[user_id]}@{extra[username]} | "
                "{name}:{function}:{line} | "
                "{message}\n"
                "{exception}"
            ),
            level="ERROR",
            enqueue=True,
            backtrace=True,
            diagnose=True
        )
        
        # é…ç½®é»˜è®¤ä¸Šä¸‹æ–‡
        logger.configure(
            extra={"user_id": None, "username": "system"}
        )
    
    def _setup_csv_logging(self):
        """è®¾ç½® CSV æ ¼å¼æ—¥å¿—(å…¼å®¹ç°æœ‰æŸ¥è¯¢å·¥å…·) - å­˜å‚¨åœ¨å½“å¤©æ—¥æœŸæ–‡ä»¶å¤¹ä¸‹"""
        def csv_sink(message):
            """CSV æ ¼å¼ sink - çº¿ç¨‹å®‰å…¨"""
            try:
                # æ£€æŸ¥æ˜¯å¦è·¨å¤©
                self._check_and_update_log_dir()
                
                record = message.record
                csv_file = self.current_log_dir / "app_logs.csv"
                
                # åˆå§‹åŒ– CSV æ–‡ä»¶(å¦‚æœä¸å­˜åœ¨)
                file_exists = csv_file.exists()
                
                if not file_exists:
                    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
                        writer = csv.writer(f)
                        writer.writerow([
                            'timestamp', 'level', 'user_id', 'username',
                            'module', 'function', 'line_number', 'message',
                            'exception_type', 'stack_trace', 'extra_data'
                        ])
                
                # å†™å…¥æ—¥å¿—è®°å½•
                with open(csv_file, 'a', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    
                    # å¤„ç†å¼‚å¸¸ä¿¡æ¯
                    exception_type = ''
                    stack_trace = ''
                    if record['exception']:
                        exception_type = record['exception'].type.__name__
                        # æ ¼å¼åŒ–å †æ ˆä¿¡æ¯(ç§»é™¤è¿‡é•¿çš„å †æ ˆ)
                        stack_lines = str(record['exception']).split('\n')
                        stack_trace = '\n'.join(stack_lines[:20])
                    
                    writer.writerow([
                        record['time'].strftime('%Y-%m-%d %H:%M:%S.%f')[:-3],
                        record['level'].name,
                        record['extra'].get('user_id', ''),
                        record['extra'].get('username', ''),
                        record['name'],
                        record['function'],
                        record['line'],
                        record['message'],
                        exception_type,
                        stack_trace,
                        json.dumps(record['extra'].get('extra_data', {}), ensure_ascii=False)
                    ])
            except Exception as e:
                # å¤‡ç”¨æ—¥å¿—è®°å½•(é¿å…æ—¥å¿—ç³»ç»Ÿæœ¬èº«å‡ºé”™)
                print(f"CSV æ—¥å¿—å†™å…¥å¤±è´¥: {e}")
        
        # æ·»åŠ  CSV sink
        logger.add(
            csv_sink,
            level="INFO",
            enqueue=True  # å¼‚æ­¥å†™å…¥
        )
    
    def _start_cleanup_task(self):
        """å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡(æ¸…ç†è¿‡æœŸçš„æ—¥å¿—æ–‡ä»¶å¤¹)"""
        def cleanup_worker():
            """åå°æ¸…ç†çº¿ç¨‹"""
            while True:
                try:
                    # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œæ¸…ç†
                    now = datetime.now()
                    next_run = now.replace(hour=2, minute=0, second=0, microsecond=0)
                    if next_run <= now:
                        next_run += timedelta(days=1)
                    
                    sleep_seconds = (next_run - now).total_seconds()
                    threading.Event().wait(sleep_seconds)
                    
                    # æ‰§è¡Œæ¸…ç†
                    self._cleanup_old_log_folders()
                    
                except Exception as e:
                    logger.error(f"æ—¥å¿—æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")
                    # å‡ºé”™åç­‰å¾…1å°æ—¶å†é‡è¯•
                    threading.Event().wait(3600)
        
        # å¯åŠ¨åå°çº¿ç¨‹
        cleanup_thread = threading.Thread(target=cleanup_worker, daemon=True, name="LogCleanup")
        cleanup_thread.start()
        logger.debug("ğŸ§¹ æ—¥å¿—æ¸…ç†åå°ä»»åŠ¡å·²å¯åŠ¨")
    
    def _cleanup_old_log_folders(self):
        """æ¸…ç†è¿‡æœŸçš„æ—¥å¿—æ–‡ä»¶å¤¹"""
        try:
            cutoff_date = datetime.now() - timedelta(days=self.max_log_days)
            deleted_count = 0
            
            # éå†æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹
            for log_folder in self.log_base_dir.iterdir():
                if not log_folder.is_dir():
                    continue
                
                try:
                    # è§£ææ–‡ä»¶å¤¹å(æ ¼å¼: YYYY-MM-DD)
                    folder_date = datetime.strptime(log_folder.name, '%Y-%m-%d')
                    
                    # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                    if folder_date < cutoff_date:
                        # åˆ é™¤æ•´ä¸ªæ–‡ä»¶å¤¹
                        import shutil
                        shutil.rmtree(log_folder)
                        deleted_count += 1
                        logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤è¿‡æœŸæ—¥å¿—æ–‡ä»¶å¤¹: {log_folder.name}")
                
                except (ValueError, OSError) as e:
                    logger.warning(f"è·³è¿‡æ— æ•ˆçš„æ—¥å¿—æ–‡ä»¶å¤¹: {log_folder.name} - {e}")
                    continue
            
            if deleted_count > 0:
                logger.success(f"âœ… æ—¥å¿—æ¸…ç†å®Œæˆ,å…±åˆ é™¤ {deleted_count} ä¸ªè¿‡æœŸæ–‡ä»¶å¤¹")
            else:
                logger.debug("âœ… æ—¥å¿—æ¸…ç†å®Œæˆ,æ— è¿‡æœŸæ–‡ä»¶å¤¹")
        
        except Exception as e:
            logger.error(f"æ¸…ç†æ—¥å¿—æ–‡ä»¶å¤¹å¤±è´¥: {e}")
    
    def _get_user_context(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰ç”¨æˆ·ä¸Šä¸‹æ–‡ - æ”¹è¿›ç‰ˆ
        
        ä¿®å¤è¯´æ˜:
        - å¢åŠ äº†æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
        - åŒºåˆ†ä¸åŒçš„æœªç™»å½•çŠ¶æ€: guest(æœªç™»å½•) vs anonymous(è·å–å¤±è´¥)
        """
        try:
            from auth.auth_manager import auth_manager
            user = auth_manager.current_user
            
            if user:
                return {
                    'user_id': user.id,
                    'username': user.username
                }
            else:
                # æœªç™»å½•çŠ¶æ€,è¿”å› guest
                return {'user_id': None, 'username': 'system'}
                
        except ImportError:
            # auth æ¨¡å—æœªåŠ è½½
            return {'user_id': None, 'username': 'system'}
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸,è®°å½•é”™è¯¯åŸå› 
            print(f"âš ï¸ è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return {'user_id': None, 'username': 'anonymous'}
    
    def _bind_context(self, extra_data: Optional[Dict] = None, depth: int = 0):
        """
        ç»‘å®šç”¨æˆ·ä¸Šä¸‹æ–‡åˆ°æ—¥å¿— - ä¿®å¤ç‰ˆ
        
        å…³é”®ä¿®å¤:
        ä½¿ç”¨ opt(depth=depth) è®© Loguru æ­£ç¡®è¿½è¸ªè°ƒç”¨æ ˆä½ç½®
        
        Args:
            extra_data: é¢å¤–æ•°æ®
            depth: è°ƒç”¨æ ˆæ·±åº¦
                   - 0: å½“å‰å‡½æ•° (_bind_context)
                   - 1: è°ƒç”¨è€… (å¦‚ log_info)
                   - 2: è°ƒç”¨è€…çš„è°ƒç”¨è€… (å…¨å±€å‡½æ•° -> ç±»æ–¹æ³•)
        
        Returns:
            ç»‘å®šäº†ä¸Šä¸‹æ–‡çš„ logger å®ä¾‹
        """
        context = self._get_user_context()
        if extra_data:
            context['extra_data'] = extra_data
        
        # ğŸ”§ å…³é”®ä¿®å¤: ä½¿ç”¨ opt(depth=depth) æ­£ç¡®è¿½è¸ªè°ƒç”¨æ ˆ
        return logger.opt(depth=depth).bind(**context)
    
    # =========================================================================
    # æ ¸å¿ƒæ—¥å¿—æ–¹æ³• - ä¿®å¤ç‰ˆ (depth=1)
    # =========================================================================
    
    def log_trace(self, message: str, extra_data: Optional[str] = None):
        """è®°å½•è¿½è¸ªæ—¥å¿— (æœ€è¯¦ç»†)"""
        extra = json.loads(extra_data) if extra_data else {}
        # depth=1: è·³è¿‡å½“å‰å‡½æ•°,è®°å½•è°ƒç”¨è€…ä½ç½®
        self._bind_context(extra, depth=1).trace(message)
    
    def log_debug(self, message: str, extra_data: Optional[str] = None):
        """è®°å½•è°ƒè¯•æ—¥å¿—"""
        extra = json.loads(extra_data) if extra_data else {}
        self._bind_context(extra, depth=1).debug(message)
    
    def log_info(self, message: str, extra_data: Optional[str] = None):
        """è®°å½•ä¿¡æ¯æ—¥å¿— (å…¼å®¹ç°æœ‰ API)"""
        extra = json.loads(extra_data) if extra_data else {}
        self._bind_context(extra, depth=1).info(message)
    
    def log_success(self, message: str, extra_data: Optional[str] = None):
        """è®°å½•æˆåŠŸæ—¥å¿—"""
        extra = json.loads(extra_data) if extra_data else {}
        self._bind_context(extra, depth=1).success(message)
    
    def log_warning(self, message: str, extra_data: Optional[str] = None):
        """è®°å½•è­¦å‘Šæ—¥å¿—"""
        extra = json.loads(extra_data) if extra_data else {}
        self._bind_context(extra, depth=1).warning(message)
    
    def log_error(self, message: str, exception: Optional[Exception] = None, 
                  extra_data: Optional[str] = None):
        """è®°å½•é”™è¯¯æ—¥å¿— (å…¼å®¹ç°æœ‰ API)"""
        extra = json.loads(extra_data) if extra_data else {}
        log_func = self._bind_context(extra, depth=1)
        
        if exception:
            log_func.opt(exception=exception).error(message)
        else:
            log_func.error(message)
    
    def log_critical(self, message: str, exception: Optional[Exception] = None,
                     extra_data: Optional[str] = None):
        """è®°å½•ä¸¥é‡é”™è¯¯æ—¥å¿—"""
        extra = json.loads(extra_data) if extra_data else {}
        log_func = self._bind_context(extra, depth=1)
        
        if exception:
            log_func.opt(exception=exception).critical(message)
        else:
            log_func.critical(message)
    
    # =========================================================================
    # å®‰å…¨æ‰§è¡Œæ–¹æ³• - å…¼å®¹ç°æœ‰ API
    # =========================================================================
    
    def safe(self, func: Callable, *args, return_value: Any = None,
             show_error: bool = True, error_msg: str = None, **kwargs) -> Any:
        """ä¸‡èƒ½å®‰å…¨æ‰§è¡Œå‡½æ•° (å…¼å®¹ç°æœ‰ API)"""
        try:
            self.log_info(f"    â”‚   â”œâ”€â”€safeå¼€å§‹å®‰å…¨æ‰§è¡Œå‡½æ•°: {func.__name__}")
            result = func(*args, **kwargs)
            self.log_info(f"    â”‚   â”œâ”€â”€safeå®‰å…¨å‡½æ•°æ‰§è¡ŒæˆåŠŸ: {func.__name__}")
            return result
            
        except Exception as e:
            error_message = error_msg or f"å‡½æ•° {func.__name__} æ‰§è¡Œå¤±è´¥: {str(e)}"
            self.log_error(error_message, exception=e)
            
            if show_error:
                try:
                    ui.notify(error_message, type='negative', timeout=5000)
                except Exception:
                    print(f"é”™è¯¯æç¤ºæ˜¾ç¤ºå¤±è´¥: {error_message}")
            
            return return_value
    
    @contextmanager
    def db_safe(self, operation_name: str = "æ•°æ®åº“æ“ä½œ"):
        """æ•°æ®åº“æ“ä½œå®‰å…¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (å…¼å®¹ç°æœ‰ API)"""
        from auth.database import get_db
        
        try:
            with get_db() as db:
                yield db
                
        except Exception as e:
            self.log_error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {operation_name}", exception=e)
            try:
                ui.notify(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {operation_name}", type='negative')
            except:
                pass
            raise
    
    def safe_protect(self, name: str = None, error_msg: str = None, 
                     return_on_error: Any = None):
        """é¡µé¢/å‡½æ•°ä¿æŠ¤è£…é¥°å™¨ (å…¼å®¹ç°æœ‰ API)"""
        def decorator(func: Callable) -> Callable:
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                func_name = name or func.__name__
                
                try:
                    self.log_info(f"â”œâ”€â”€å¼€å§‹é¡µé¢ä¿æŠ¤æ‰§è¡Œï¼š{func_name} ")
                    result = func(*args, **kwargs)
                    self.log_info(f"â”œâ”€â”€å®Œæˆé¡µé¢ä¿æŠ¤æ‰§è¡Œ: {func_name} ")
                    return result
                
                except Exception as e:
                    error_message = error_msg or f"é¡µé¢ {func_name} åŠ è½½å¤±è´¥"
                    self.log_error(f"{func_name}æ‰§è¡Œå¤±è´¥", exception=e)
                    
                    try:
                        with ui.row().classes('fit items-center justify-center'):
                            # æ˜¾ç¤ºå‹å¥½çš„é”™è¯¯é¡µé¢
                            # ç§»é™¤ 'w-full' å’Œ 'min-h-96'ï¼Œè®©å†…å®¹åŒºåŸŸæ ¹æ®å†…éƒ¨å…ƒç´ å¤§å°è‡ªé€‚åº”
                            with ui.column().classes('p-6 text-center'): # åªéœ€è¦ text-center æ¥å¯¹ column å†…éƒ¨çš„æ–‡æœ¬å’Œè¡Œå…ƒç´ è¿›è¡Œæ°´å¹³å±…ä¸­
                                ui.icon('error_outline', size='4rem').classes('text-red-500 mb-4')
                                ui.label(f'{func_name} æ‰§è¡Œå¤±è´¥').classes('text-2xl font-bold text-red-600 mb-2')
                                ui.label(error_message).classes('text-gray-600 mb-4')

                                # æŒ‰é’®è¡Œï¼Œéœ€è¦è®©å®ƒåœ¨ column ä¸­ä¿æŒå±…ä¸­
                                # 'mx-auto' æ˜¯ä½¿å—çº§å…ƒç´ ï¼ˆå¦‚ ui.rowï¼‰æ°´å¹³å±…ä¸­çš„ Tailwind ç±»
                                with ui.row().classes('gap-2 mt-6 mx-auto'):
                                    ui.button('åˆ·æ–°é¡µé¢', icon='refresh',
                                                on_click=lambda: ui.navigate.reload()).classes('bg-blue-500 text-white')
                                    ui.button('è¿”å›é¦–é¡µ', icon='home',
                                                on_click=lambda: ui.navigate.to('/workbench')).classes('bg-gray-500 text-white')
                        
                    except Exception:
                        print(f"é”™è¯¯é¡µé¢æ˜¾ç¤ºå¤±è´¥: {error_message}")
                    
                    return return_on_error
            
            return wrapper
        return decorator
    
    # =========================================================================
    # Loguru ç‰¹è‰²åŠŸèƒ½ - æ–°å¢æ–¹æ³•
    # =========================================================================
    
    def catch(self, func: Callable = None, *, message: str = None, 
              show_ui_error: bool = True):
        """Loguru å¼‚å¸¸æ•è·è£…é¥°å™¨"""
        def decorator(f: Callable) -> Callable:
            @functools.wraps(f)
            @logger.catch(message=message or f"Error in {f.__name__}")
            def wrapper(*args, **kwargs):
                try:
                    return f(*args, **kwargs)
                except Exception as e:
                    if show_ui_error:
                        try:
                            ui.notify(f"{f.__name__} æ‰§è¡Œå¤±è´¥", type='negative')
                        except:
                            pass
                    raise
            return wrapper
        
        # æ”¯æŒ @catch å’Œ @catch() ä¸¤ç§ç”¨æ³•
        if func is None:
            return decorator
        else:
            return decorator(func)
    
    def get_logger(self, name: str = None):
        """
        è·å–ç»‘å®šç”¨æˆ·ä¸Šä¸‹æ–‡çš„ logger å®ä¾‹
        ä½¿ç”¨æ–¹æ³•:
            log = handler.get_logger("my_module")
            log.info("This is a message")
        """
        context = self._get_user_context()
        bound_logger = logger.bind(**context)
        
        if name:
            bound_logger = bound_logger.bind(module_name=name)
        
        return bound_logger

# =============================================================================
# å…¨å±€å•ä¾‹å®ä¾‹
# =============================================================================

_exception_handler = None
_handler_lock = threading.Lock()

def get_exception_handler() -> LoguruExceptionHandler:
    """è·å–å¼‚å¸¸å¤„ç†å™¨å•ä¾‹(çº¿ç¨‹å®‰å…¨)"""
    global _exception_handler
    if _exception_handler is None:
        with _handler_lock:
            if _exception_handler is None:
                _exception_handler = LoguruExceptionHandler()
    return _exception_handler

# =============================================================================
# å¯¹å¤–æš´éœ²çš„æ ¸å¿ƒå‡½æ•° - å®Œå…¨å…¼å®¹ç°æœ‰ API (ä¿®å¤ç‰ˆ depth=2)
# =============================================================================

def log_trace(message: str, extra_data: Optional[str] = None):
    """è®°å½•è¿½è¸ªæ—¥å¿—"""
    handler = get_exception_handler()
    extra = json.loads(extra_data) if extra_data else {}
    # ğŸ”§ depth=2: è·³è¿‡å½“å‰å‡½æ•° + _bind_context,è®°å½•çœŸå®è°ƒç”¨è€…
    handler._bind_context(extra, depth=2).trace(message)

def log_debug(message: str, extra_data: Optional[str] = None):
    """è®°å½•è°ƒè¯•æ—¥å¿—"""
    handler = get_exception_handler()
    extra = json.loads(extra_data) if extra_data else {}
    handler._bind_context(extra, depth=2).debug(message)

def log_info(message: str, extra_data: Optional[str] = None):
    """è®°å½•ä¿¡æ¯æ—¥å¿— (å…¼å®¹ç°æœ‰ API)"""
    handler = get_exception_handler()
    extra = json.loads(extra_data) if extra_data else {}
    handler._bind_context(extra, depth=2).info(message)

def log_success(message: str, extra_data: Optional[str] = None):
    """è®°å½•æˆåŠŸæ—¥å¿—"""
    handler = get_exception_handler()
    extra = json.loads(extra_data) if extra_data else {}
    handler._bind_context(extra, depth=2).success(message)

def log_warning(message: str, extra_data: Optional[str] = None):
    """è®°å½•è­¦å‘Šæ—¥å¿—"""
    handler = get_exception_handler()
    extra = json.loads(extra_data) if extra_data else {}
    handler._bind_context(extra, depth=2).warning(message)

def log_error(message: str, exception: Optional[Exception] = None,
              extra_data: Optional[str] = None):
    """è®°å½•é”™è¯¯æ—¥å¿— (å…¼å®¹ç°æœ‰ API)"""
    handler = get_exception_handler()
    extra = json.loads(extra_data) if extra_data else {}
    log_func = handler._bind_context(extra, depth=2)
    
    if exception:
        log_func.opt(exception=exception).error(message)
    else:
        log_func.error(message)

def log_critical(message: str, exception: Optional[Exception] = None,
                 extra_data: Optional[str] = None):
    """è®°å½•ä¸¥é‡é”™è¯¯æ—¥å¿—"""
    handler = get_exception_handler()
    extra = json.loads(extra_data) if extra_data else {}
    log_func = handler._bind_context(extra, depth=2)
    
    if exception:
        log_func.opt(exception=exception).critical(message)
    else:
        log_func.critical(message)

def safe(func: Callable, *args, return_value: Any = None,
         show_error: bool = True, error_msg: str = None, **kwargs) -> Any:
    """ä¸‡èƒ½å®‰å…¨æ‰§è¡Œå‡½æ•° (å…¼å®¹ç°æœ‰ API)"""
    handler = get_exception_handler()
    return handler.safe(func, *args, return_value=return_value,
                       show_error=show_error, error_msg=error_msg, **kwargs)

@contextmanager
def db_safe(operation_name: str = "æ•°æ®åº“æ“ä½œ"):
    """æ•°æ®åº“æ“ä½œå®‰å…¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (å…¼å®¹ç°æœ‰ API)"""
    handler = get_exception_handler()
    with handler.db_safe(operation_name) as db:
        yield db

def safe_protect(name: str = None, error_msg: str = None, return_on_error: Any = None):
    """é¡µé¢/å‡½æ•°ä¿æŠ¤è£…é¥°å™¨ (å…¼å®¹ç°æœ‰ API)"""
    handler = get_exception_handler()
    return handler.safe_protect(name, error_msg, return_on_error)

def catch(func: Callable = None, *, message: str = None, show_ui_error: bool = True):
    """Loguru å¼‚å¸¸æ•è·è£…é¥°å™¨"""
    handler = get_exception_handler()
    return handler.catch(func, message=message, show_ui_error=show_ui_error)

def get_logger(name: str = None):
    """è·å–ç»‘å®šç”¨æˆ·ä¸Šä¸‹æ–‡çš„ logger å®ä¾‹"""
    handler = get_exception_handler()
    return handler.get_logger(name)

# =============================================================================
# æ—¥å¿—æŸ¥è¯¢å’Œç®¡ç†å·¥å…·å‡½æ•° - å…¼å®¹ç°æœ‰ API (é€‚é…æ—¥æœŸæ–‡ä»¶å¤¹ç»“æ„)
# =============================================================================

def get_log_files(days: int = 7) -> List[Dict]:
    """è·å–æœ€è¿‘å‡ å¤©çš„æ—¥å¿—æ–‡ä»¶åˆ—è¡¨ (å…¼å®¹ç°æœ‰ API)"""
    handler = get_exception_handler()
    log_files = []
    
    for i in range(days):
        date = datetime.now() - timedelta(days=i)
        date_str = date.strftime('%Y-%m-%d')
        date_folder = handler.log_base_dir / date_str
        
        if not date_folder.exists():
            continue
        
        # CSV æ ¼å¼æ—¥å¿—æ–‡ä»¶
        csv_file = date_folder / 'app_logs.csv'
        if csv_file.exists():
            log_files.append({
                'date': date_str,
                'file_path': csv_file,
                'size': csv_file.stat().st_size,
                'type': 'csv'
            })
        
        # æ™®é€šæ—¥å¿—æ–‡ä»¶
        log_file = date_folder / 'app.log'
        if log_file.exists():
            log_files.append({
                'date': date_str,
                'file_path': log_file,
                'size': log_file.stat().st_size,
                'type': 'log'
            })
        
        # é”™è¯¯æ—¥å¿—æ–‡ä»¶
        error_file = date_folder / 'error.log'
        if error_file.exists():
            log_files.append({
                'date': date_str,
                'file_path': error_file,
                'size': error_file.stat().st_size,
                'type': 'error'
            })
    
    return log_files

def get_today_errors(limit: int = 50) -> List[Dict]:
    """è·å–ä»Šå¤©çš„é”™è¯¯æ—¥å¿— (å…¼å®¹ç°æœ‰ API)"""
    handler = get_exception_handler()
    today_folder = handler.current_log_dir
    csv_file = today_folder / "app_logs.csv"
    
    if not csv_file.exists():
        return []
    
    try:
        errors = []
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row['level'] in ['ERROR', 'CRITICAL']:
                    errors.append(row)
        
        return errors[-limit:] if len(errors) > limit else errors
    
    except Exception as e:
        print(f"è¯»å–é”™è¯¯æ—¥å¿—å¤±è´¥: {e}")
        return []

def get_today_logs_by_level(level: str = "INFO", limit: int = 100) -> List[Dict]:
    """æ ¹æ®æ—¥å¿—çº§åˆ«è·å–ä»Šå¤©çš„æ—¥å¿—"""
    handler = get_exception_handler()
    today_folder = handler.current_log_dir
    csv_file = today_folder / "app_logs.csv"
    
    if not csv_file.exists():
        return []
    
    try:
        logs = []
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row['level'] == level.upper():
                    logs.append(row)
        
        return logs[-limit:] if len(logs) > limit else logs
    
    except Exception as e:
        print(f"è¯»å–æ—¥å¿—å¤±è´¥: {e}")
        return []

def cleanup_logs(days_to_keep: int = 30):
    """æ‰‹åŠ¨æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶å¤¹ (å…¼å®¹ç°æœ‰ API)"""
    handler = get_exception_handler()
    handler.max_log_days = days_to_keep
    handler._cleanup_old_log_folders()
    log_info(f"æ—¥å¿—æ¸…ç†å®Œæˆ: ä¿ç•™ {days_to_keep} å¤©")

def get_log_statistics(days: int = 7) -> Dict[str, Any]:
    """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
    handler = get_exception_handler()
    stats = {
        'total_logs': 0,
        'error_count': 0,
        'warning_count': 0,
        'info_count': 0,
        'by_date': {},
        'by_level': {},
        'by_user': {}
    }
    
    for i in range(days):
        date = datetime.now() - timedelta(days=i)
        date_str = date.strftime('%Y-%m-%d')
        date_folder = handler.log_base_dir / date_str
        csv_file = date_folder / 'app_logs.csv'
        
        if csv_file.exists():
            try:
                with open(csv_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        stats['total_logs'] += 1
                        
                        level = row['level']
                        stats['by_level'][level] = stats['by_level'].get(level, 0) + 1
                        
                        if level == 'ERROR':
                            stats['error_count'] += 1
                        elif level == 'WARNING':
                            stats['warning_count'] += 1
                        elif level == 'INFO':
                            stats['info_count'] += 1
                        
                        stats['by_date'][date_str] = stats['by_date'].get(date_str, 0) + 1
                        
                        username = row.get('username', 'unknown')
                        stats['by_user'][username] = stats['by_user'].get(username, 0) + 1
            
            except Exception as e:
                print(f"è¯»å– {csv_file} å¤±è´¥: {e}")
    
    return stats

def get_log_folder_info() -> Dict[str, Any]:
    """è·å–æ—¥å¿—æ–‡ä»¶å¤¹ä¿¡æ¯"""
    handler = get_exception_handler()
    
    folder_info = {
        'base_dir': str(handler.log_base_dir),
        'current_dir': str(handler.current_log_dir),
        'folder_count': 0,
        'total_size': 0,
        'folders': []
    }
    
    try:
        for log_folder in sorted(handler.log_base_dir.iterdir(), reverse=True):
            if not log_folder.is_dir():
                continue
            
            try:
                folder_size = sum(f.stat().st_size for f in log_folder.rglob('*') if f.is_file())
                
                folder_info['folders'].append({
                    'name': log_folder.name,
                    'path': str(log_folder),
                    'size': folder_size,
                    'file_count': len(list(log_folder.iterdir()))
                })
                
                folder_info['folder_count'] += 1
                folder_info['total_size'] += folder_size
            
            except Exception as e:
                print(f"è¯»å–æ–‡ä»¶å¤¹ {log_folder} å¤±è´¥: {e}")
    
    except Exception as e:
        print(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤¹ä¿¡æ¯å¤±è´¥: {e}")
    
    return folder_info

# =============================================================================
# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
# =============================================================================

if __name__ == "__main__":
    print("=" * 70)
    print("ğŸš€ åŸºäº Loguru çš„å¢å¼ºå¼‚å¸¸å¤„ç†å™¨ - æµ‹è¯• (v2.2 ä¿®å¤ç‰ˆ)")
    print("=" * 70)
    
    # 1. åŸºç¡€æ—¥å¿—è®°å½•
    print("\nğŸ“ æµ‹è¯• 1: åŸºç¡€æ—¥å¿—è®°å½•")
    log_trace("è¿™æ˜¯è¿½è¸ªæ—¥å¿—")
    log_debug("è¿™æ˜¯è°ƒè¯•æ—¥å¿—")
    log_info("åº”ç”¨å¯åŠ¨", extra_data='{"version": "2.2.0", "env": "production"}')
    log_success("åˆå§‹åŒ–æˆåŠŸ")
    log_warning("è¿™æ˜¯è­¦å‘Šæ—¥å¿—")
    log_error("è¿™æ˜¯é”™è¯¯æ—¥å¿—")
    log_critical("è¿™æ˜¯ä¸¥é‡é”™è¯¯æ—¥å¿—")
    
    # 2. æ¨¡æ‹Ÿä¸šåŠ¡ä»£ç è°ƒç”¨
    print("\nğŸ¯ æµ‹è¯• 2: æ¨¡æ‹Ÿä¸šåŠ¡ä»£ç è°ƒç”¨(éªŒè¯ module/function/line æ˜¯å¦æ­£ç¡®)")
    
    def business_function():
        """æ¨¡æ‹Ÿä¸šåŠ¡å‡½æ•°"""
        log_info("ä¸šåŠ¡å‡½æ•°ä¸­çš„ä¿¡æ¯æ—¥å¿—")
        log_warning("ä¸šåŠ¡å‡½æ•°ä¸­çš„è­¦å‘Šæ—¥å¿—")
        
        try:
            raise ValueError("æµ‹è¯•å¼‚å¸¸")
        except Exception as e:
            log_error("ä¸šåŠ¡å‡½æ•°ä¸­å‡ºç°é”™è¯¯", exception=e)
    
    # è°ƒç”¨ä¸šåŠ¡å‡½æ•°
    business_function()
    
    # 3. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
    print("\nğŸ“‚ æµ‹è¯• 3: æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶")
    log_files = get_log_files(1)
    print(f"ä»Šå¤©çš„æ—¥å¿—æ–‡ä»¶: {len(log_files)} ä¸ª")
    for file in log_files:
        print(f"  - {file['date']} ({file['type']}): {file['size']} bytes")
    
    # 4. æ—¥å¿—ç»Ÿè®¡
    print("\nğŸ“ˆ æµ‹è¯• 4: æ—¥å¿—ç»Ÿè®¡")
    stats = get_log_statistics(days=1)
    print(f"æ€»æ—¥å¿—æ•°: {stats['total_logs']}")
    print(f"é”™è¯¯æ•°: {stats['error_count']}")
    print(f"æŒ‰çº§åˆ«ç»Ÿè®¡: {stats['by_level']}")
    
    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆ! è¯·æ£€æŸ¥ logs/YYYY-MM-DD/app_logs.csv æ–‡ä»¶")
    print("âœ… éªŒè¯: module åº”è¯¥æ˜¾ç¤º '__main__'")
    print("âœ… éªŒè¯: function åº”è¯¥æ˜¾ç¤º 'business_function'")
    print("âœ… éªŒè¯: line_number åº”è¯¥æ˜¾ç¤º business_function ä¸­çš„å®é™…è¡Œå·")
    print("=" * 70)
```

- **common\safe_openai_client_pool.py**
```python
"""
SafeOpenAIClientPool - çº¿ç¨‹å®‰å…¨çš„OpenAIå®¢æˆ·ç«¯è¿æ¥æ± 

æ–‡ä»¶è·¯å¾„: \common\safe_openai_client_pool.py

ä¸“ä¸ºNiceGUIåº”ç”¨è®¾è®¡çš„OpenAIå®¢æˆ·ç«¯ç®¡ç†å™¨ï¼Œæä¾›çº¿ç¨‹å®‰å…¨çš„å®¢æˆ·ç«¯åˆ›å»ºã€ç¼“å­˜å’Œç®¡ç†åŠŸèƒ½ã€‚

ç‰¹æ€§ï¼š
- å¼‚æ­¥é”ä¿è¯å¹¶å‘å®‰å…¨ï¼Œé¿å…é‡å¤åˆ›å»ºå®¢æˆ·ç«¯
- æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼ŒæŒ‰æ¨¡å‹é…ç½®ç¼“å­˜å®¢æˆ·ç«¯å®ä¾‹
- è‡ªåŠ¨å†…å­˜ç®¡ç†ï¼Œæ”¯æŒLRUç¼“å­˜æ¸…ç†
- å®Œå–„çš„é”™è¯¯å¤„ç†å’Œç”¨æˆ·å‹å¥½çš„æç¤º
- è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯å’Œæ€§èƒ½ç›‘æ§
- é…ç½®æ›´æ–°æ—¶è‡ªåŠ¨åˆ·æ–°å®¢æˆ·ç«¯
- æ”¯æŒé…ç½®å‡½æ•°å’Œé…ç½®å­—å…¸ä¸¤ç§ä¼ å‚æ–¹å¼

è®¾è®¡åŸåˆ™ï¼š
1. çº¿ç¨‹å®‰å…¨ï¼šä½¿ç”¨asyncio.Lock()é˜²æ­¢å¹¶å‘åˆ›å»º
2. å†…å­˜é«˜æ•ˆï¼šé™åˆ¶ç¼“å­˜å¤§å°ï¼Œè‡ªåŠ¨æ¸…ç†æ—§å®¢æˆ·ç«¯
3. ç”¨æˆ·å‹å¥½ï¼šæä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯å’ŒçŠ¶æ€æç¤º
4. å¯è§‚æµ‹æ€§ï¼šè¯¦ç»†çš„æ—¥å¿—å’Œç»Ÿè®¡ä¿¡æ¯
5. å®¹é”™æ€§ï¼šä¼˜é›…å¤„ç†å„ç§å¼‚å¸¸æƒ…å†µ
6. å…¼å®¹æ€§ï¼šæ”¯æŒå¤šç§é…ç½®ä¼ é€’æ–¹å¼
"""

import asyncio
import time
from datetime import datetime, timedelta
from typing import Dict, Optional, Set, Any, Union, Callable
from openai import OpenAI


class SafeOpenAIClientPool:
    """
    çº¿ç¨‹å®‰å…¨çš„OpenAIå®¢æˆ·ç«¯è¿æ¥æ± 
    
    ä½¿ç”¨åœºæ™¯ï¼š
    - NiceGUIåº”ç”¨çš„èŠå¤©åŠŸèƒ½
    - å¤šç”¨æˆ·å¹¶å‘è®¿é—®OpenAI API
    - åŠ¨æ€æ¨¡å‹åˆ‡æ¢
    - é…ç½®çƒ­æ›´æ–°
    """
    
    def __init__(self, max_clients: int = 20, client_ttl_hours: int = 24):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯æ± 
        
        Args:
            max_clients: æœ€å¤§ç¼“å­˜çš„å®¢æˆ·ç«¯æ•°é‡ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
            client_ttl_hours: å®¢æˆ·ç«¯ç”Ÿå­˜æ—¶é—´ï¼ˆå°æ—¶ï¼‰ï¼Œè¶…æ—¶è‡ªåŠ¨æ¸…ç†
        """
        # å®¢æˆ·ç«¯ç¼“å­˜
        self._clients: Dict[str, OpenAI] = {}
        self._client_configs: Dict[str, Dict] = {}  # ç¼“å­˜é…ç½®ä¿¡æ¯ï¼Œç”¨äºéªŒè¯
        self._creation_times: Dict[str, datetime] = {}  # è®°å½•åˆ›å»ºæ—¶é—´
        self._access_times: Dict[str, datetime] = {}  # è®°å½•æœ€åè®¿é—®æ—¶é—´
        self._access_counts: Dict[str, int] = {}  # è®°å½•è®¿é—®æ¬¡æ•°
        
        # å¹¶å‘æ§åˆ¶
        self._lock = asyncio.Lock()  # å¼‚æ­¥é”ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
        self._creating: Set[str] = set()  # æ­£åœ¨åˆ›å»ºçš„å®¢æˆ·ç«¯æ ‡è®°
        
        # é…ç½®å‚æ•°
        self._max_clients = max_clients
        self._client_ttl = timedelta(hours=client_ttl_hours)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._total_requests = 0
        self._cache_hits = 0
        self._cache_misses = 0
        self._creation_count = 0
        self._cleanup_count = 0
        
        print(f"ğŸ”§ SafeOpenAIClientPool å·²åˆå§‹åŒ–")
        print(f"   æœ€å¤§ç¼“å­˜: {max_clients} ä¸ªå®¢æˆ·ç«¯")
        print(f"   å®¢æˆ·ç«¯TTL: {client_ttl_hours} å°æ—¶")
    
    async def get_client(self, model_key: str, config_getter_func=None) -> Optional[OpenAI]:
        """
        è·å–æŒ‡å®šæ¨¡å‹çš„OpenAIå®¢æˆ·ç«¯å®ä¾‹
        
        Args:
            model_key: æ¨¡å‹é”®å (å¦‚ 'deepseek-chat', 'moonshot-v1-8k')
            config_getter_func: é…ç½®è·å–æ–¹å¼ï¼Œæ”¯æŒï¼š
                              - å‡½æ•°ï¼šfunction(model_key) -> dict
                              - å­—å…¸ï¼šç›´æ¥ä½¿ç”¨è¯¥é…ç½®
                              - Noneï¼šå°è¯•è‡ªåŠ¨å¯¼å…¥é…ç½®å‡½æ•°
            
        Returns:
            OpenAIå®¢æˆ·ç«¯å®ä¾‹ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        self._total_requests += 1
        start_time = time.time()
        
        try:
            # æ¸…ç†è¿‡æœŸçš„å®¢æˆ·ç«¯
            await self._cleanup_expired_clients()
            
            # å¿«é€Ÿè·¯å¾„ï¼šç¼“å­˜å‘½ä¸­ä¸”æœ‰æ•ˆ
            if await self._is_client_valid(model_key):
                self._cache_hits += 1
                self._access_counts[model_key] = self._access_counts.get(model_key, 0) + 1
                self._access_times[model_key] = datetime.now()
                
                elapsed_ms = (time.time() - start_time) * 1000
                print(f"âš¡ ç¼“å­˜å‘½ä¸­: {model_key} ({elapsed_ms:.1f}ms)")
                return self._clients[model_key]
            
            # æ…¢é€Ÿè·¯å¾„ï¼šéœ€è¦åˆ›å»ºæ–°å®¢æˆ·ç«¯
            self._cache_misses += 1
            return await self._create_client_safe(model_key, config_getter_func, start_time)
            
        except Exception as e:
            elapsed_ms = (time.time() - start_time) * 1000
            error_msg = f"è·å–OpenAIå®¢æˆ·ç«¯å¤±è´¥ ({model_key}): {str(e)}"
            print(f"âŒ {error_msg} ({elapsed_ms:.1f}ms)")
            return None
    
    async def _is_client_valid(self, model_key: str) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜çš„å®¢æˆ·ç«¯æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
        
        Args:
            model_key: æ¨¡å‹é”®å
            
        Returns:
            å®¢æˆ·ç«¯æ˜¯å¦æœ‰æ•ˆ
        """
        if model_key not in self._clients:
            return False
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        creation_time = self._creation_times.get(model_key)
        if creation_time and datetime.now() - creation_time > self._client_ttl:
            print(f"â° å®¢æˆ·ç«¯å·²è¿‡æœŸ: {model_key}")
            await self._remove_client(model_key)
            return False
        
        # ç®€å•çš„æœ‰æ•ˆæ€§æ£€æŸ¥
        try:
            client = self._clients[model_key]
            return hasattr(client, 'api_key') and hasattr(client, 'base_url')
        except Exception:
            return False
    
    async def _create_client_safe(self, model_key: str, config_getter_func, start_time: float) -> Optional[OpenAI]:
        """
        çº¿ç¨‹å®‰å…¨çš„å®¢æˆ·ç«¯åˆ›å»ºæ–¹æ³•
        
        Args:
            model_key: æ¨¡å‹é”®å
            config_getter_func: é…ç½®è·å–æ–¹å¼
            start_time: å¼€å§‹æ—¶é—´ï¼ˆç”¨äºæ€§èƒ½ç»Ÿè®¡ï¼‰
            
        Returns:
            åˆ›å»ºçš„OpenAIå®¢æˆ·ç«¯å®ä¾‹
        """
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨åˆ›å»ºï¼Œé¿å…é‡å¤åˆ›å»º
        if model_key in self._creating:
            print(f"â³ ç­‰å¾…å®¢æˆ·ç«¯åˆ›å»ºå®Œæˆ: {model_key}")
            
            # ç­‰å¾…å…¶ä»–åç¨‹å®Œæˆåˆ›å»ºï¼ˆæœ€å¤šç­‰å¾…10ç§’ï¼‰
            wait_start = time.time()
            while model_key in self._creating and (time.time() - wait_start) < 10:
                await asyncio.sleep(0.01)
            
            # æ£€æŸ¥æ˜¯å¦åˆ›å»ºæˆåŠŸ
            if model_key in self._clients:
                elapsed_ms = (time.time() - start_time) * 1000
                print(f"âœ… ç­‰å¾…å®Œæˆï¼Œè·å–å®¢æˆ·ç«¯: {model_key} ({elapsed_ms:.1f}ms)")
                return self._clients[model_key]
            else:
                print(f"âš ï¸ ç­‰å¾…å®¢æˆ·ç«¯åˆ›å»ºè¶…æ—¶æˆ–å¤±è´¥: {model_key}")
                return None
        
        # è·å–å¼‚æ­¥é”ï¼Œç¡®ä¿åªæœ‰ä¸€ä¸ªåç¨‹åˆ›å»ºå®¢æˆ·ç«¯
        async with self._lock:
            # åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼
            if model_key in self._clients:
                elapsed_ms = (time.time() - start_time) * 1000
                print(f"ğŸ”„ é”å†…ç¼“å­˜å‘½ä¸­: {model_key} ({elapsed_ms:.1f}ms)")
                return self._clients[model_key]
            
            # æ ‡è®°ä¸ºæ­£åœ¨åˆ›å»º
            self._creating.add(model_key)
            
            try:
                return await self._create_client_internal(model_key, config_getter_func, start_time)
            finally:
                # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½è¦æ¸…é™¤åˆ›å»ºæ ‡è®°
                self._creating.discard(model_key)
    
    async def _create_client_internal(self, model_key: str, config_getter_func, start_time: float) -> Optional[OpenAI]:
        """
        å†…éƒ¨å®¢æˆ·ç«¯åˆ›å»ºæ–¹æ³•
        
        Args:
            model_key: æ¨¡å‹é”®å
            config_getter_func: é…ç½®è·å–æ–¹å¼
            start_time: å¼€å§‹æ—¶é—´
            
        Returns:
            åˆ›å»ºçš„OpenAIå®¢æˆ·ç«¯å®ä¾‹
        """
        print(f"ğŸ”¨ å¼€å§‹åˆ›å»ºOpenAIå®¢æˆ·ç«¯: {model_key}")
        
        try:
            # è·å–æ¨¡å‹é…ç½®
            config = await self._get_model_config(model_key, config_getter_func)
            if not config:
                raise ValueError(f"æ— æ³•è·å–æ¨¡å‹é…ç½®: {model_key}")
            
            # éªŒè¯å¿…è¦çš„é…ç½®é¡¹
            api_key = config.get('api_key', '').strip()
            base_url = config.get('base_url', '').strip()
            
            if not api_key:
                raise ValueError(f"æ¨¡å‹ {model_key} ç¼ºå°‘æœ‰æ•ˆçš„ API Key")
            
            if not base_url:
                raise ValueError(f"æ¨¡å‹ {model_key} ç¼ºå°‘æœ‰æ•ˆçš„ Base URL")
            
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å·²æ»¡ï¼Œå¦‚éœ€è¦åˆ™æ¸…ç†
            await self._check_and_cleanup_cache()
            
            # åˆ›å»ºOpenAIå®¢æˆ·ç«¯å®ä¾‹
            client = OpenAI(
                api_key=api_key,
                base_url=base_url,
                timeout=config.get('timeout', 60),
                max_retries=config.get('max_retries', 3)
            )
            
            # ç¼“å­˜å®¢æˆ·ç«¯å’Œç›¸å…³ä¿¡æ¯
            current_time = datetime.now()
            self._clients[model_key] = client
            self._client_configs[model_key] = config.copy()
            self._creation_times[model_key] = current_time
            self._access_times[model_key] = current_time
            self._access_counts[model_key] = 1
            self._creation_count += 1
            
            elapsed_ms = (time.time() - start_time) * 1000
            model_name = config.get('name', model_key)
            
            print(f"âœ… å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: {model_name} ({elapsed_ms:.1f}ms)")
            print(f"   API Key: {api_key[:12]}...")
            print(f"   Base URL: {base_url}")
            
            return client
            
        except Exception as e:
            error_msg = f"åˆ›å»ºOpenAIå®¢æˆ·ç«¯å¤±è´¥ ({model_key}): {str(e)}"
            print(f"âŒ {error_msg}")
            raise
    
    async def _get_model_config(self, model_key: str, config_getter_func) -> Optional[Dict]:
        """
        è·å–æ¨¡å‹é…ç½®ä¿¡æ¯ï¼ˆæ”¯æŒå‡½æ•°å’Œå­—å…¸ä¸¤ç§æ–¹å¼ï¼‰
        
        Args:
            model_key: æ¨¡å‹é”®å
            config_getter_func: å¤–éƒ¨æä¾›çš„é…ç½®è·å–æ–¹å¼
            
        Returns:
            æ¨¡å‹é…ç½®å­—å…¸
        """
        if config_getter_func:
            if callable(config_getter_func):
                # ä½¿ç”¨å¤–éƒ¨æä¾›çš„é…ç½®è·å–å‡½æ•°
                try:
                    config = config_getter_func(model_key)
                    if isinstance(config, dict):
                        return config
                    else:
                        print(f"âš ï¸ é…ç½®è·å–å‡½æ•°è¿”å›äº†éå­—å…¸ç±»å‹: {type(config)}")
                        return None
                except Exception as e:
                    print(f"âš ï¸ è°ƒç”¨é…ç½®è·å–å‡½æ•°å¤±è´¥: {str(e)}")
                    return None
            elif isinstance(config_getter_func, dict):
                # ç›´æ¥ä½¿ç”¨é…ç½®å­—å…¸
                return config_getter_func
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„config_getter_funcç±»å‹: {type(config_getter_func)}")
                return None
        
        # å°è¯•è‡ªåŠ¨å¯¼å…¥é…ç½®è·å–å‡½æ•°
        try:
            # å‡è®¾é…ç½®å‡½æ•°åœ¨æŸä¸ªå·²çŸ¥æ¨¡å—ä¸­
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…é¡¹ç›®ç»“æ„è°ƒæ•´å¯¼å…¥è·¯å¾„
            from menu_pages.enterprise_archive.chat_component.config import get_model_config
            return get_model_config(model_key)
        except ImportError:
            print(f"âš ï¸ æ— æ³•è‡ªåŠ¨å¯¼å…¥é…ç½®è·å–å‡½æ•°ï¼Œè¯·æä¾› config_getter_func å‚æ•°")
            return None
    
    async def _check_and_cleanup_cache(self):
        """
        æ£€æŸ¥ç¼“å­˜å¤§å°å¹¶åœ¨éœ€è¦æ—¶æ¸…ç†æœ€å°‘ä½¿ç”¨çš„å®¢æˆ·ç«¯
        """
        if len(self._clients) >= self._max_clients:
            print(f"ğŸ§¹ ç¼“å­˜å·²æ»¡ ({len(self._clients)}/{self._max_clients})ï¼Œå¼€å§‹æ¸…ç†...")
            
            # æ‰¾åˆ°æœ€å°‘ä½¿ç”¨çš„å®¢æˆ·ç«¯ï¼ˆLRUç­–ç•¥ï¼‰
            if self._access_times:
                # æŒ‰æœ€åè®¿é—®æ—¶é—´æ’åºï¼Œç§»é™¤æœ€ä¹…æœªä½¿ç”¨çš„
                oldest_model = min(self._access_times.items(), key=lambda x: x[1])[0]
                await self._remove_client(oldest_model)
                self._cleanup_count += 1
                print(f"ğŸ—‘ï¸ å·²æ¸…ç†æœ€ä¹…æœªä½¿ç”¨çš„å®¢æˆ·ç«¯: {oldest_model}")
    
    async def _cleanup_expired_clients(self):
        """
        æ¸…ç†è¿‡æœŸçš„å®¢æˆ·ç«¯
        """
        current_time = datetime.now()
        expired_clients = []
        
        for model_key, creation_time in self._creation_times.items():
            if current_time - creation_time > self._client_ttl:
                expired_clients.append(model_key)
        
        for model_key in expired_clients:
            await self._remove_client(model_key)
            self._cleanup_count += 1
            print(f"â° å·²æ¸…ç†è¿‡æœŸå®¢æˆ·ç«¯: {model_key}")
    
    async def _remove_client(self, model_key: str):
        """
        ç§»é™¤æŒ‡å®šçš„å®¢æˆ·ç«¯åŠå…¶ç›¸å…³ä¿¡æ¯
        
        Args:
            model_key: è¦ç§»é™¤çš„æ¨¡å‹é”®å
        """
        self._clients.pop(model_key, None)
        self._client_configs.pop(model_key, None)
        self._creation_times.pop(model_key, None)
        self._access_times.pop(model_key, None)
        self._access_counts.pop(model_key, None)
    
    async def update_client(self, model_key: str, config_getter_func=None) -> Optional[OpenAI]:
        """
        æ›´æ–°æŒ‡å®šæ¨¡å‹çš„å®¢æˆ·ç«¯ï¼ˆé…ç½®å˜æ›´æ—¶ä½¿ç”¨ï¼‰
        
        Args:
            model_key: æ¨¡å‹é”®å
            config_getter_func: é…ç½®è·å–æ–¹å¼
            
        Returns:
            æ›´æ–°åçš„å®¢æˆ·ç«¯å®ä¾‹
        """
        print(f"ğŸ”„ æ›´æ–°å®¢æˆ·ç«¯: {model_key}")
        
        # ç§»é™¤æ—§å®¢æˆ·ç«¯
        await self._remove_client(model_key)
        
        # åˆ›å»ºæ–°å®¢æˆ·ç«¯
        return await self.get_client(model_key, config_getter_func)
    
    async def clear_cache(self) -> int:
        """
        æ¸…ç©ºæ‰€æœ‰ç¼“å­˜çš„å®¢æˆ·ç«¯
        
        Returns:
            æ¸…ç†çš„å®¢æˆ·ç«¯æ•°é‡
        """
        async with self._lock:
            cleared_count = len(self._clients)
            
            self._clients.clear()
            self._client_configs.clear()
            self._creation_times.clear()
            self._access_times.clear()
            self._access_counts.clear()
            
            self._cleanup_count += cleared_count
            
            print(f"ğŸ§¹ å·²æ¸…ç©ºæ‰€æœ‰å®¢æˆ·ç«¯ç¼“å­˜ï¼Œå…±æ¸…ç† {cleared_count} ä¸ªå®¢æˆ·ç«¯")
            return cleared_count
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–å®¢æˆ·ç«¯æ± çš„ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            åŒ…å«å„ç§ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        cache_hit_rate = (self._cache_hits / self._total_requests * 100) if self._total_requests > 0 else 0.0
        
        return {
            # åŸºæœ¬çŠ¶æ€
            'cached_clients': len(self._clients),
            'creating_clients': len(self._creating),
            'max_clients': self._max_clients,
            'models': list(self._clients.keys()),
            
            # æ€§èƒ½ç»Ÿè®¡
            'total_requests': self._total_requests,
            'cache_hits': self._cache_hits,
            'cache_misses': self._cache_misses,
            'cache_hit_rate': f"{cache_hit_rate:.1f}%",
            'creation_count': self._creation_count,
            'cleanup_count': self._cleanup_count,
            
            # è¯¦ç»†ä¿¡æ¯
            'access_counts': self._access_counts.copy(),
            'creation_times': {
                k: v.strftime('%H:%M:%S') for k, v in self._creation_times.items()
            },
            'access_times': {
                k: v.strftime('%H:%M:%S') for k, v in self._access_times.items()
            }
        }
    
    def print_stats(self):
        """
        æ‰“å°è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯åˆ°æ§åˆ¶å°
        """
        stats = self.get_stats()
        
        print(f"\nğŸ“Š SafeOpenAIClientPool ç»Ÿè®¡ä¿¡æ¯")
        print(f"{'=' * 50}")
        print(f"ç¼“å­˜çŠ¶æ€: {stats['cached_clients']}/{stats['max_clients']} ä¸ªå®¢æˆ·ç«¯")
        print(f"æ­£åœ¨åˆ›å»º: {stats['creating_clients']} ä¸ª")
        print(f"æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
        print(f"ç¼“å­˜å‘½ä¸­ç‡: {stats['cache_hit_rate']}")
        print(f"åˆ›å»ºæ¬¡æ•°: {stats['creation_count']}")
        print(f"æ¸…ç†æ¬¡æ•°: {stats['cleanup_count']}")
        
        if stats['models']:
            print(f"\nğŸ“± å·²ç¼“å­˜çš„æ¨¡å‹:")
            for model in stats['models']:
                access_count = stats['access_counts'].get(model, 0)
                creation_time = stats['creation_times'].get(model, 'Unknown')
                access_time = stats['access_times'].get(model, 'Unknown')
                print(f"  â€¢ {model}")
                print(f"    è®¿é—®æ¬¡æ•°: {access_count}")
                print(f"    åˆ›å»ºæ—¶é—´: {creation_time}")
                print(f"    æœ€åè®¿é—®: {access_time}")
        else:
            print(f"\næš‚æ— ç¼“å­˜çš„å®¢æˆ·ç«¯")
        
        print()
    
    def __repr__(self):
        """è¿”å›å®¢æˆ·ç«¯æ± çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"<SafeOpenAIClientPool(clients={len(self._clients)}/{self._max_clients}, hit_rate={self.get_stats()['cache_hit_rate']})>"


# ==================== å…¨å±€å•ä¾‹å®ä¾‹ ====================

# å…¨å±€å®¢æˆ·ç«¯æ± å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_global_client_pool: Optional[SafeOpenAIClientPool] = None

def get_openai_client_pool(max_clients: int = 20, client_ttl_hours: int = 24) -> SafeOpenAIClientPool:
    """
    è·å–å…¨å±€OpenAIå®¢æˆ·ç«¯æ± å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    Args:
        max_clients: æœ€å¤§ç¼“å­˜å®¢æˆ·ç«¯æ•°é‡ï¼ˆä»…åœ¨é¦–æ¬¡è°ƒç”¨æ—¶ç”Ÿæ•ˆï¼‰
        client_ttl_hours: å®¢æˆ·ç«¯ç”Ÿå­˜æ—¶é—´å°æ—¶æ•°ï¼ˆä»…åœ¨é¦–æ¬¡è°ƒç”¨æ—¶ç”Ÿæ•ˆï¼‰
        
    Returns:
        å…¨å±€å®¢æˆ·ç«¯æ± å®ä¾‹
    """
    global _global_client_pool
    if _global_client_pool is None:
        _global_client_pool = SafeOpenAIClientPool(max_clients, client_ttl_hours)
    return _global_client_pool


# ==================== ä¾¿æ·å‡½æ•° ====================

async def get_openai_client(model_key: str, config_getter_func=None) -> Optional[OpenAI]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–OpenAIå®¢æˆ·ç«¯ï¼ˆé‡æ„ç‰ˆæœ¬ï¼‰
    
    Args:
        model_key: æ¨¡å‹é”®å
        config_getter_func: é…ç½®è·å–æ–¹å¼ï¼Œæ”¯æŒï¼š
                          - å‡½æ•°ï¼šfunction(model_key) -> dict
                          - å­—å…¸ï¼šç›´æ¥ä½¿ç”¨è¯¥é…ç½®
                          - Noneï¼šå°è¯•è‡ªåŠ¨å¯¼å…¥é…ç½®å‡½æ•°
        
    Returns:
        OpenAIå®¢æˆ·ç«¯å®ä¾‹
    """
    pool = get_openai_client_pool()
    
    # é‡æ„ï¼šæ”¯æŒå‡½æ•°å’Œå­—å…¸ä¸¤ç§æ–¹å¼
    if config_getter_func is None:
        # ä¿æŒåŸæœ‰é€»è¾‘ï¼šå°è¯•è‡ªåŠ¨å¯¼å…¥
        return await pool.get_client(model_key, None)
    elif callable(config_getter_func):
        # åŸæœ‰é€»è¾‘ï¼šä¼ é€’å‡½æ•°
        return await pool.get_client(model_key, config_getter_func)
    elif isinstance(config_getter_func, dict):
        # æ–°å¢é€»è¾‘ï¼šç›´æ¥ä¼ é€’é…ç½®å­—å…¸
        def dict_config_getter(key: str) -> dict:
            return config_getter_func
        return await pool.get_client(model_key, dict_config_getter)
    else:
        # å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—å…¸å¤„ç†
        print(f"âš ï¸ æœªçŸ¥çš„é…ç½®ç±»å‹: {type(config_getter_func)}, å°è¯•ä½œä¸ºå­—å…¸å¤„ç†")
        def fallback_config_getter(key: str) -> dict:
            return config_getter_func if isinstance(config_getter_func, dict) else {}
        return await pool.get_client(model_key, fallback_config_getter)

async def clear_openai_cache() -> int:
    """
    ä¾¿æ·å‡½æ•°ï¼šæ¸…ç©ºOpenAIå®¢æˆ·ç«¯ç¼“å­˜
    
    Returns:
        æ¸…ç†çš„å®¢æˆ·ç«¯æ•°é‡
    """
    pool = get_openai_client_pool()
    return await pool.clear_cache()

def print_openai_stats():
    """
    ä¾¿æ·å‡½æ•°ï¼šæ‰“å°OpenAIå®¢æˆ·ç«¯æ± ç»Ÿè®¡ä¿¡æ¯
    """
    pool = get_openai_client_pool()
    pool.print_stats()


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

async def example_usage():
    """
    ä½¿ç”¨ç¤ºä¾‹ï¼ˆå±•ç¤ºé‡æ„åçš„å¤šç§ä½¿ç”¨æ–¹å¼ï¼‰
    """
    print("ğŸš€ SafeOpenAIClientPool é‡æ„ç‰ˆæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # æ–¹å¼1ï¼šä½¿ç”¨é…ç½®è·å–å‡½æ•°ï¼ˆåŸæœ‰æ–¹å¼ï¼‰
    def mock_get_model_config(model_key: str):
        configs = {
            'deepseek-chat': {
                'name': 'DeepSeek Chat',
                'api_key': 'sk-deepseek-test-key',
                'base_url': 'https://api.deepseek.com/v1',
                'timeout': 60
            },
            'moonshot-v1-8k': {
                'name': 'Moonshot 8K',
                'api_key': 'sk-moonshot-test-key',
                'base_url': 'https://api.moonshot.cn/v1',
                'timeout': 60
            }
        }
        return configs.get(model_key)
    
    print("\nğŸ“‹ æ–¹å¼1ï¼šä½¿ç”¨é…ç½®è·å–å‡½æ•°")
    client1 = await get_openai_client('deepseek-chat', mock_get_model_config)
    if client1:
        print("âœ… æˆåŠŸè·å–å®¢æˆ·ç«¯ï¼ˆé…ç½®å‡½æ•°æ–¹å¼ï¼‰")
    
    # æ–¹å¼2ï¼šç›´æ¥ä¼ é€’é…ç½®å­—å…¸ï¼ˆæ–°å¢æ–¹å¼ï¼‰
    config_dict = {
        'name': 'Claude Chat',
        'api_key': 'sk-claude-test-key',
        'base_url': 'https://api.anthropic.com/v1',
        'timeout': 60
    }
    
    print("\nğŸ“‹ æ–¹å¼2ï¼šç›´æ¥ä¼ é€’é…ç½®å­—å…¸")
    client2 = await get_openai_client('claude-3-sonnet', config_dict)
    if client2:
        print("âœ… æˆåŠŸè·å–å®¢æˆ·ç«¯ï¼ˆé…ç½®å­—å…¸æ–¹å¼ï¼‰")
    
    # æ–¹å¼3ï¼šè‡ªåŠ¨å¯¼å…¥é…ç½®å‡½æ•°ï¼ˆä¿æŒå…¼å®¹ï¼‰
    print("\nğŸ“‹ æ–¹å¼3ï¼šè‡ªåŠ¨å¯¼å…¥é…ç½®å‡½æ•°")
    client3 = await get_openai_client('gpt-4', None)
    if client3:
        print("âœ… æˆåŠŸè·å–å®¢æˆ·ç«¯ï¼ˆè‡ªåŠ¨å¯¼å…¥æ–¹å¼ï¼‰")
    else:
        print("âš ï¸ è‡ªåŠ¨å¯¼å…¥å¤±è´¥ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºç¤ºä¾‹ç¯å¢ƒä¸­æ²¡æœ‰é…ç½®æ¨¡å—ï¼‰")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print_openai_stats()
    
    # æµ‹è¯•ç¼“å­˜å‘½ä¸­
    print(f"\nğŸ”„ æµ‹è¯•ç¼“å­˜å‘½ä¸­...")
    start_time = time.time()
    cached_client = await get_openai_client('deepseek-chat', mock_get_model_config)
    elapsed_ms = (time.time() - start_time) * 1000
    print(f"ç¼“å­˜å‘½ä¸­è€—æ—¶: {elapsed_ms:.1f}ms")
    
    # æ¸…ç†ç¼“å­˜
    print(f"\nğŸ§¹ æ¸…ç†ç¼“å­˜...")
    cleared_count = await clear_openai_cache()
    print(f"å·²æ¸…ç† {cleared_count} ä¸ªå®¢æˆ·ç«¯")
    
    print_openai_stats()

if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    import asyncio
    asyncio.run(example_usage())
```
